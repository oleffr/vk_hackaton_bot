
# RAG Project

Этот проект позволяет создавать и обновлять базу знаний для RAG (Retrieval-Augmented Generation) системы на основе веб-страниц и PDF-файлов, а также запускать в консоли чат-бота для работы с этой базой.
Для использования данного проекта требуется LM Studio для запуска хоста моделей.

### Основные возможности

- **Создание или обновление базы знаний из PDF-файлов** (`pdfs` директория или указанный путь)
- **Создание или обновление базы знаний из URL** (`seed_urls.txt`)
- **Запуск чат-бота**, который использует базу знаний для ответов на вопросы
- **Справка по командам**, доступная через `main.py`


### Общий синтаксис

```bash
python main.py <command> [options]
```

### Доступные команды

1. **update_pdf** – добавить или обновить PDF в базе знаний
   ```bash
   python main.py pdf --pdf_dir ./pdfs --out ./kb_output
   ```
   **Ньюансы:** 
   - Добавляет только новые PDF-файлы или новые чанки текста.
   - Сохраняет метаданные для каждого документа.
   - Использует LM Studio для генерации эмбеддингов.

2. **update_url** – добавить или обновить веб-страницы в базе знаний
   ```bash
   python main.py url --seeds ./seed_urls.txt --out ./kb_output --max_pages 200 --delay 0.1
   ```
   **Ньюансы:** 
   - Рекурсивно обходит страницы, ограничено `--max-pages`.
   - Игнорирует внешние домены, email, телефоны.
   - Обновляет существующую FAISS базу без дублирования чанков.
   - Создаёт/дополняет `urls.txt` с уникальными URL.

3. **chat** – запустить RAG чат-бота
   ```bash
   python main.py chat --out ./kb_output
   ```
   **Ньюансы:** 
   - Использует текущую FAISS базу.
   - Возвращает ответы с источниками (URL или PDF) по чанкам.
   - Поддерживает exit/выход/quit для завершения.

4. **help** – вывод справки
   ```bash
   python main.py help
   ```

## Настройки LM Studio

- **LM_API** – адрес локального API LM Studio (`http://localhost:1234/v1`)
- **LM_API_KEY** – ключ для LM Studio (`lm-studio`)
- **EMBEDDING_MODEL** – модель эмбеддингов для LM Studio (`text-embedding-paraphrase-multilingual-minilm-l12-v2.gguf`)
- **MODEL_NAME** – модель LLM для ответов (`Qwen2.5-3B-Instruct`)

Все эти данные можно получить из ответа http://localhost:1234/v1/models

## Примечания

- Все базы сохраняются в папке, указанной через `--out` (по умолчанию `kb_output`).
- FAISS база обновляется инкрементально: добавляются только новые URL или PDF, без дубликаты.
- Рекурсивный краул веб-страниц игнорирует внешние домены и недоступные ссылки.
- Прогресс обработки и добавления чанков отображается через прогресс-бар из `tqdm`.

## Установка зависимостей

```bash
pip install -r requirements.txt
```

## Пример полного рабочего процесса

```bash
# Обновляем базу из PDF
python main.py pdf --pdf_dir ./pdfs --out ./kb_output

# Обновляем базу из URL
python main.py url --seeds ./seed_urls.txt --out ./kb_output --max_pages 200 --delay 0.1

# Запускаем чат-бот
python main.py chat --out ./kb_output
```

Напоминание как создать venv:
```
python -m venv myenv
.\venv\Scripts\Activate.ps1
```
